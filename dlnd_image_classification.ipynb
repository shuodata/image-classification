{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/cifar/cifar-10-python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAHF9JREFUeJzt3UmPZOl1HuAvxsyMrKzKqsqau6rY\nA5vNbropkjJJmYIsUIBXWtn+BV7YO/8Yr73wymtDNAwIggwSMEmBNMeW2Wz2VOzumquyco6M2Qtt\nzI2Bc5gChYPn2Z88Ed+9cd+8q7ezWq0aAFBT9w/9AQCAfzyCHgAKE/QAUJigB4DCBD0AFCboAaAw\nQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh/T/0B/jH8l/+\nw79fZebGx9PwTK+f+3+pc/tGeGZvtJHa9faFYWruk1/+LDzznR/+PLVrbzILz/R6ybPvdFJzg7X1\n8MylKzupXec34t/t83eupHb9+be+Hp6Zz+LXq7XWnu0fpeYGWxfDM+9+8NvUrr/97g/jQ8nnwNog\nN3dhMAjPDPuL1K5p4lrPZ7nfWFstU2NrvbXwzMkq/rxvrbUXp/F46eZ+Lu073/+75EH+P7t/3z8A\nAPzTJegBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGFl\n2+te3P84NddfxJuTBv1UUV67v5qEZ94f5yqQ3v7iK6m55TT+Ga/t5NraNlLfLXf22fa6k0n8PPZ3\nX6R2HXXiTWOT03Fq15e/+o3wzOzkNLXr2fPceVxbjzc3LqcHqV0ba/H7atlyrWtXt86l5r70ymvh\nmadP7qd2jceH4Zmjo1xLYevGW/laa22tPw/P3Lx+IbVrNrwanvngV/dSu86CN3oAKEzQA0Bhgh4A\nChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUFjZUpuPT9dScyfj/fDMsJMr\n92iLeKFCtzNMrXr228epuZ88+Cw88+snudKS1SReSpEtp1lfX0/NzebxopnWzf0/vb4Rv4f3xrli\nlR+983545sblXCHIZJ67ZpkCo7XkE24wSHzG3NG3L7z6amruc3fuhme2t0apXY8e3gvPLGe55+K5\nizdSc4tBvPRotJYr3rm5Ey8i+rSXO/uz4I0eAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQ\nA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtdeNeriFrtxtvJ+ssJqldl/vx4z93/mJq1+lxvJWv\ntdb2DuPf7eB0ltq1Spz9YpFok2ut9ZKfsZ/533gWb11rrbXjafzsz61yu370i1+GZ15/7bXUrjde\nvZOa6w/j7V+f+1yuGe54OQjPPH74NLXr4HCcmmvrm+GRP/6zt1Orfv7j74VnxvN4G2VrrR3Oci1v\nz4/jz8ZL41zD3q3eYXjm9Cjb2vj780YPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAw\nQQ8AhQl6AChM0ANAYYIeAAorW2qz1tlNzd0YxYsYtlu8AKO11i5d3AjPfLyKlym01trmxjI1t9aJ\nl6SMOrnbara5Fp+Z58ppTie5IqJF4n/jjVGupGO4Fr+vrt++kdp186Xb4ZlnR7lCkEcHuRKXb3zj\n6+GZ3cePUrv+9b/5Vnjmf/z3v07t+uEP/i41d+dLXw3PfPvtr6V2fXj/o/DMx9//cWrX/nQrNXc0\njz/jvvjP42fYWmvj2YvwzM7OemrXWfBGDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGg\nMEEPAIUJegAoTNADQGGCHgAKE/QAUFjZ9rrhZu6rvbJ1NTzz8iq368Iw0Wa0/1lq12g73gzXWmvH\nw5PwzHKwSO364z+KN0lduxq/Xq219tEHH6TmPv3kfnim28u1G67m8Xa49W7u7P/kG/Gzfxq/NVpr\nrf3oe99Nzb333p3wzGKc/JCbF8Mje8e5RsSjWe5964OHz8Mzx8teatfxPP4Zn+zlzmOyfi419/m7\nr4Rntq/dTO16+jx+9t/+9lupXWfBGz0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIE\nPQAUJugBoDBBDwCFCXoAKEzQA0BhZdvrjqa5xrALvc3wzOzZi9SuT/fiTWh/+uU3UrvG0+PU3K1l\nfGZ9tErt+uZ2/OzfvLKT2nWyzH3GZ2vxFsCT/dz9sZjGZ/rTw9Suu598HJ7Z2Jundl26sp2am/39\nz8Iz2ebAH/7q3fDMew8epHadznMtb/c/iTdZPnn+NLXr61/5Znjm7vbt1K7/9F//W2puOn4UnvnJ\nj5+ldj1+/GF45qt/kXt2nwVv9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgsLKlNld666m5W60Xnjl/fiu16+cv4qUULyb7qV13r99Izf3bJy+HZwYHuQKd\ny+/Hz2Ptw4epXYvlLDX3uU58ZrBIDLXWuv34Pbzo5EpcJj/6aXjmQrKMZbkTLy9qrbXFPNGwdLBI\n7TrfOxeemRzn7vtL8UdOa6210Wocnjl49NvUrltffD08s7WZewZ//dVbqbkn+/EWqEdHJ6ldJye7\n4ZmP3n8/tesseKMHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGg\nMEEPAIUJegAorGx73Rtbo9Tc5vNn4ZleN9Gq1Vp7/aWXwjOHj5+mdrVVrkHtVmcVnhkNc7t6iUao\nzjL++VprLd5z9Q8m3cT/xsO11K7BKv7d+pmGt9baoBtv85tt5WrXVie51rv5JH4ei5a7F69143fI\ntzdyrXzTzjA1t7h5LTyzfu9eatdJ5iMmWz3feuO11NyNk/g1uzGbp3a9/urN8MxrO/FGxLPijR4A\nChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFFa21Gb3wUep\nuck8XoIx7uWKRE4uxEsONk7i5SOttXb67oepuUVvEZ6Zb+Zuq24vXkqxlixx6bT11Nw8UQ60WOY+\n42owiM+kNuXm+ldfSe3a2su9X5wmLtn07sXUrovzo/DM5mmuKmm+lytWOXqyH545efD91K6H//sX\n4Znzb72e2vX8Ua64azq6FJ6Zj1Or2snzF+GZg0G2Suv3540eAAoT9ABQmKAHgMIEPQAUJugBoDBB\nDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtdc+P9lJznx6fhmfmy1z71LBzPTwz\nuriT2vV8fJiau95bC89snOb+f1wcxJv5JtNcm1/byZ3j5uuvhWdOE01orbV29OwgPLO2jLfrtdZa\nbzIJz0ye5u6ptpZrlOtsx9se+51cn9/yIP4c2Hgr1+bXhvHv1Vproyfx6rXj+/dTu/Z+/UF4ZvnJ\n49SurUtbqbnd7XhL5PNHud/mwyefhWdeHt5I7ToL3ugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKK9te9+I03j7VWmuPTuJtRrOD49SunWtXwjOr\n21dTu9Yu5hqh1g7izXz9B09Tu6ZHJ+GZoxZvrGqttcW5jdTc4O6d8Ey/s0jt2tyOn8fsN5+kds0S\nLYCn3Vxz4NafvZmaO9l7Fh9679epXW2eeAd6mPh8rbXJMte0Obh+Mzxz/V9+M7VrbaMXntn9zYep\nXdsn8V2ttXbhbrxp85NHuYa9jV68FXEwGKZ2nQVv9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQ\nA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgsLKlNrdvv5Sa6358PzyzMU6taotpvBhhrTNI7XpxfJCa\n+8Gnn4Vnbp4epna90eIHOUmUsbTW2vh+/Dq31tr0p7+K72rx69xaa51bt8Izp69fT+06mY/CM2+/\nmiunOe6eS82NH9wLzwz3c+VW8/PxApLpJ8lCoce5UqzB1SfhmZNruVKswaUL4ZmLf/HV1K69Tx+m\n5rZ34mU4Xz13N7Xrb/7Xi/DM2na8xOyseKMHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0\nAFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAorGx73fWb11Jzh/efhWdGFzupXa2zFh4ZdHO7Hj57npr7\nz7/4P+GZL1zOtZP9x/XN8Mwo+a/q6vgoNbf7Try9bvdKvPmrtdY+msRbzabJprybr98Mz9y5mPte\n04ePU3PnEq1mneU0tasdxn9na92N1KqD8UlqbvHRR+GZ1YNHqV0vtuLPqs0v5BpEb778amru9FH8\nvroyij9zWmvtK196LTxz++XceZwFb/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT\n9ABQmKAHgMIEPQAUJugBoLCypTb7ixepuf5qPzwz6OeOcdqLF5DszcepXbvjXNnJfBX/bgeDXLnH\n/cEoPLO9mqd2Tbu5udVqEp7ZX+ZKSz57Ei+1Od9dT+16kbhkf3X/r1K7vnDrVmru1Uvx73Z57Xpq\n1/G9++GZxTh+vVprbbXI3YsvXjxN7Mo9B6br8VKb2X68IKy11qa/fD81N0oUOk3WB6ldd998Kzwz\ne/Db1K6z4I0eAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9\nABQm6AGgsLLtdcPVMjXXX87CMzvdXAPStBdvrerPpqldJ6e587h15Up45qWXb6d23T9KNPOtcm1c\nw2RrVWce/8lMl/HGu9Zau3F5JzzTzxWhtYOnj8Izq91cK9+D57mWt/3RMDxzZxL/PbfWWvdZvL2u\njXOH353n3rfG8/g5nixyz49VohVxNO6kdj28/1lqbtSJ7zue567Z9iQ+t/P266ldZ8EbPQAUJugB\noDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAorGypzcZ4lJp7ML8Q\nnrnaPU3tujjeC8/0nzxM7ZofvkjNffHNl8Mzd77w+dSu3V+8F5650emldrVBrgxnsIr/b7xxlCtx\n6bf4ZxyNNlK7fvPhvfDMznHuPeGVz11KzX02jBfUPP4g93vZONwNz3TmuXuqs8jdw6eJUqxpN3fN\npsfxXbuLw9Su0eh8au5wGi+POp7krtnu/cfhmf6d66ldZ8EbPQAUJugBoDBBDwCFCXoAKEzQA0Bh\ngh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGFl2+v2j+NNV6219t39eEvT/HJqVfvW\nchqe2XjyKLVrfXaSmvvK174dnrl5+7XUru/86J3wzP4k1xy46Ofuj1miLW9j1UntOv0sfq17l3LN\ncK9c3AnPnC72U7v6m8PU3Nt/+vXwzG680Owf5n7yJDwzWeaa0Jb9tdTcOHFfbW4mH1Ybm+GR8TDX\nyre8fDE1d9ri+x49jbcUttba/t6z8MyLX7+f2vWXqanf5Y0eAAoT9ABQmKAHgMIEPQAUJugBoDBB\nDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtddODB6m5D54/Ds+MZ7k2ru2X4o1h\nXx7kWte2+vFWvtZae/n27fDM+XO5BrXJIt7mNzmJz7TW2nCwSM2druL7ht3c/TGcxq/ZeDfXxtXt\nxx8Fy16ure3x81wD44t3fxWeGa3nGtQO18/FZzZGqV2Tc1upuePj4/DMaCf329ydxlsiD+e531h3\nNk7NPXx0FN+1Hm/la621g1n8ObB5kGt7PAve6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DC\nBD0AFCboAaAwQQ8AhQl6AChM0ANAYWVLbf7V3VxZwdPdeJnFjz8+Se36m3vxkoONV3Lfa3RuLTW3\n1YsXdcwO4wUYrbW26MRLMI4nuV3rvdytv+gl/jfu5P6fXnbjc7vH8WKP1lpbncYLdIbHubOf7eWK\niFYffhKeGSXfZaaj8+GZd+aT1K57z56k5taX8ZnhMlcYM1iP/146s05q1+lerpjpeBUvB+qfG6R2\nLQbx73b34nZq11nwRg8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQ\nA0Bhgh4AChP0AFBY2fa612/mvtq/G90Jz9xeu5/a9T/fizeN/e29WWrXH929mZo7+vDj8Mxe8v/H\n3jJex7U3zTUHXhnFm65aa22x6oVnZsvcNXu6ip/Hs1G8fbG11k778fa6rU7uN7Z5IXf2y2n8M7bn\nB6lda2vxlsjPTnPNcM8Xq9Tc9UG8eW20mbs/tjbj57Ea59oNn01z59jvxZ8Fvd3c8+NLq2F45txh\n7jlwFrzRA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DC\nypbaTJJlJ5fWO+GZP3l9J7Xr2XG8tOQn9/dTu959/CI19/lEUcd0mLutVsv4/52Hp5Pcrkm8lKK1\n1gbr8e+2WuZKS1pibmNtPbXqcBUvIDm4cy216/Jbb6TmevGfS3vnr7+X2nU7cV+9dPFKalebTFNj\n6/34gezPcoUxx8/jz9PryYKlmzuXU3PDbvy3OdjNPU/vHsYLyW5vb6d2nQVv9ABQmKAHgMIEPQAU\nJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIWVba/r9HJfrTOPt1bd\n2M41hv2Lly+EZw6m8Zax1lq7t5dr8zvpxdv8rt6+ndrVG47CM6fzXDPc6eFhaq4/W4RnhoON1K74\n3dHa/PHT1K7zi3l4ZnKQu6d2Z4kautba9sWL8ZlO7l1mcBr/brc2N1O7hsn3rc7mWnxmkPuM3aN4\nw961fvz33FpriQLR1lpr3Un8t3mSfA5c6MXvj1fv5HLiLHijB4DCBD0AFCboAaAwQQ8AhQl6AChM\n0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKKxse91qlatAWi0T7WTLeONda629eSl+\n/E9vnEvtOp7kPuN8HG/L27l8JbVr/Vy8r21vmWuvm01nqbl5Ym7SyzUOdju98Mz55L/umV6t6cF+\nbtlp7jxWj56EZ15quefAoBdv89sa587jai/Xbvgi0Ui5thVvAGytteUsfmPNT/ZSuw4muVbERHld\nW06OU7tuvHk1PPPyndxz8Sx4oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DC\nBD0AFCboAaAwQQ8AhZUttVl2cv/DLFq8SKTNcwUpF/rxwo2v3N5J7Xp+uJuamz5+GJ6ZHeeKIoab\n8XKP0+R1nq1yc91l/FovZom2jdZaZxG/P+bJ85gOMuUv8eKX1lrrzHPnsegN40PdXKnNYh7/bqtk\nWc/6YpCaW82m4ZlH67mimdla/OyXa6lVbbCZO4+Tk/h5DFfL1K4rd66HZ9b7ifv3jHijB4DCBD0A\nFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKKxse91wYzM1\n11sfhWeme0epXZlWs5vb8c/XWmv/bD/XrPXu3uPwzKMHn6R2HYwPwjNHy1z71Gk39z/uYLkKz8xX\nuba27ir+8zzu5NraTlbxuX7yPWE5yV2z5SR+D3eS7XUtcZ1P+7nrvEw05bXW2nHmM65NUrtaN/7d\n1ge5+rrlIt5C11prm8v4d3vt2lZq18Vh/OxPnueaA3Of8Hd5oweAwgQ9ABQm6AGgMEEPAIUJegAo\nTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhZUttWndXmqs0xmEZ/obqVXttDsLzwwSZQqt\ntXbnRq4M5+PP4gUT08lxatdiGd+1N88VYDzr5G79rV78vuqscteskyio2c/1xbRH03hpSbeTe0/o\nJQp0srJvMoMWv86Pl/Hfc2ut7bdcGc5R4lrfSpb8bCcKuHq7h6ld1/rrqbmv3b4ennn1du7hPRrH\ni8wmybIepTYAwP+XoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCbo\nAaAwQQ8AhdVtr1vm/oeZjE/CM9k2rk6iSWo1zTVkndvcTM3tnI83Lu0+fZLadfgoPrffy13nHySb\nxi4miujOJxoRW2ttM9FeN+vmmvIO5vG502TrWra7rteNX+thom2wtdZGqU+Z29Xv5CoHR4lrvZzN\nU7umi/h5bCTvjwvncp+xzQ7CI0cvcmd/cD7+m+7Mc8+cndTU7/JGDwCFCXoAKEzQA0Bhgh4AChP0\nAFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUFjZ9rrFMtfitUrMdZINasP+MDyz\nGucakFruONrVzfhn/Ok7f5/a9fzB0/DMvJO7hZ8mO9QO5vE2v9Ei2U6W+IhryXtxNYxf526iTa61\n1jqJVr7WWuv3441hi1WynWwR/53N57m2tlXyMw4zx59sr1sm7qtuP/fQWbbcM27vaC8801vlzmOt\nuxWe6Sz/cHHrjR4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DC\nBD0AFFa21KY7iBdgtNbaINHD0EkWxnR6ieNf5IozFsdHqbkbW6PwzOVB7jMOTsfhmfPLXEHKaSf3\nP243MTfv50pLjpfxuXHyXmyJEpfePLeskywU6iYKhVarZLlVJ372uW/V2qDTy80lnh8byfv+XGJs\ns5N8DuTGWmvxwcn4OLUp8zgddePP0rPijR4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNAD\nQGGCHgAKE/QAUJigB4DCBD0AFCboAaCwuu11/dxX660S//uscu1kLdVel2vl63dz3VrnOvHGsD97\n62Zq1/5JfNfPPnmW2vVsMk/NnS7jbWiTZK/ZMnF/LJP/uy8S36ubrG3sJGveut1sNV9cL9Hy1k9+\nvI1u7lk16safBVv93OFvdePPuMvJdBklb5BBi/+mh8l7arWI7zpNtHOeFW/0AFCYoAeAwgQ9ABQm\n6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaCwsqU2bbieHIyXFXRWyTaLRPHO\nfD5LrVomL3WmvOHGKLWq/eWXb4Vnrg1yhUIfPD5IzT0+jp//i3mupON02QvPTJK34rwTv86rRPFL\na611e/Hv1VprvcRcsj+nDRIlP/1kt9VmptyqtbaWOP+1Tu5Dnu8twjMXkwU6m73cfbU+iJ9jP3cr\nttks/hw46cTP8Kx4oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCbo\nAaAwQQ8AhQl6ACiss8o2rwEA/+R5oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJig\nB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQ\nA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCbo\nAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh/xfkBwlH\nN40TWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffa28860b00>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`.\n",
    "\n",
    "\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    x_min = x.min(axis=(0, 1), keepdims=True)\n",
    "    x_max = x.max(axis=(0, 1), keepdims=True)\n",
    "    x_normalized =(x - x_min)/(x_max - x_min)\n",
    "    return x_normalized\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(np.asarray(([list(range(10))])).T)\n",
    "    return enc.transform(np.asarray([x]).T).toarray()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    #Implement Function\n",
    "       \n",
    "    return tf.placeholder(tf.float32, shape=((None,) + image_shape), name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=(None, n_classes), name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # Implement Function\n",
    "    return  tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # Implement Function\n",
    "   \n",
    "    weights_shape =  [conv_ksize[0], conv_ksize[1], int(x_tensor.get_shape()[3]), conv_num_outputs]\n",
    "    weights = tf.Variable(tf.truncated_normal(weights_shape, stddev=5e-2))\n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    conv = tf.nn.conv2d(x_tensor, weights, [1, conv_strides[0], conv_strides[1], 1], padding='SAME', name='conv')\n",
    "\n",
    "\n",
    "    pre_activation = tf.nn.bias_add(conv, bias)\n",
    "    conv1 = tf.nn.relu(pre_activation, name='conv1')\n",
    "    pool1 = tf.nn.max_pool(conv1, [1, pool_ksize[0], pool_ksize[1], 1], [1, pool_strides[0],\n",
    "                                                                         pool_strides[1], 1], padding='SAME', name='pool1')\n",
    "\n",
    "    \n",
    "    return pool1 \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "\n",
    "    fs = np.array(x_tensor.get_shape().as_list()[1:]).prod()\n",
    "    \n",
    "    return tf.reshape(x_tensor, [tf.shape(x_tensor)[0], fs])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "\n",
    "    fs = np.array(x_tensor.get_shape().as_list()[1:]).prod()\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal([fs, num_outputs], stddev=5e-2))\n",
    "    fc = tf.nn.relu(tf.matmul(x_tensor, weights) + bias, name='FC')\n",
    "    \n",
    "    return fc\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    fs = np.array(x_tensor.get_shape().as_list()[1:]).prod()\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal([fs, num_outputs], stddev=5e-2))\n",
    "    output = tf.nn.relu(tf.matmul(x_tensor, weights) + bias, name='output')\n",
    "    return output\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    conv = conv2d_maxpool(x,\n",
    "                           conv_num_outputs=62,\n",
    "                           conv_ksize=[6,6],\n",
    "                           conv_strides=[2,2],\n",
    "                           pool_ksize=[2,2],\n",
    "                           pool_strides=[2,2])\n",
    "    conv = conv2d_maxpool(conv,\n",
    "                           conv_num_outputs=30,\n",
    "                           conv_ksize=[3,3],\n",
    "                           conv_strides=[1,1],\n",
    "                           pool_ksize=[2,2],\n",
    "                           pool_strides=[1,1])\n",
    "\n",
    "    # Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    flatten_conv = flatten(conv)\n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    fc =  fully_conn(flatten_conv, 200)\n",
    "    fc =  fully_conn(flatten_conv, 100)\n",
    "    fc =  fully_conn(fc, 10)\n",
    "    \n",
    "    dropout = tf.nn.dropout(fc, keep_prob)\n",
    "    # TODO: Apply an Output Layer\n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "    return output(dropout, 10)  \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # Implement Function\n",
    "    session.run(optimizer, feed_dict={x: feature_batch,\n",
    "                                      y: label_batch,\n",
    "                                      keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # Implement Function\n",
    "    loss = sess.run(cost, feed_dict={x: feature_batch,\n",
    "                                     y: label_batch,\n",
    "                                     keep_prob: 1.})\n",
    "    valid_acc = sess.run(accuracy, feed_dict={x: valid_features,\n",
    "                                              y: valid_labels,\n",
    "                                              keep_prob: 1.})\n",
    "    print('Loss: {:>10.5f} Validation Accuracy: {:.5f}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tune Parameters\n",
    "epochs = 99\n",
    "batch_size = 256\n",
    "keep_probability = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:    2.22312 Validation Accuracy: 0.17020\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:    2.16485 Validation Accuracy: 0.26040\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:    2.13476 Validation Accuracy: 0.29620\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:    2.07451 Validation Accuracy: 0.31560\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:    2.03671 Validation Accuracy: 0.34840\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:    2.06222 Validation Accuracy: 0.32900\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:    1.98490 Validation Accuracy: 0.37060\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:    1.91456 Validation Accuracy: 0.36340\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:    1.83043 Validation Accuracy: 0.39460\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:    1.75261 Validation Accuracy: 0.41080\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:    1.70669 Validation Accuracy: 0.41420\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:    1.71426 Validation Accuracy: 0.41100\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:    1.60128 Validation Accuracy: 0.41260\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:    1.55808 Validation Accuracy: 0.42760\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:    1.56452 Validation Accuracy: 0.43560\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:    1.48393 Validation Accuracy: 0.44540\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:    1.47080 Validation Accuracy: 0.44920\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:    1.45832 Validation Accuracy: 0.46140\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:    1.44252 Validation Accuracy: 0.45840\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:    1.36523 Validation Accuracy: 0.47100\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:    1.34430 Validation Accuracy: 0.47640\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:    1.36530 Validation Accuracy: 0.45880\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:    1.31985 Validation Accuracy: 0.47160\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:    1.25898 Validation Accuracy: 0.48220\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:    1.30117 Validation Accuracy: 0.46940\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:    1.20575 Validation Accuracy: 0.50360\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:    1.24581 Validation Accuracy: 0.48360\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:    1.17947 Validation Accuracy: 0.50520\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:    1.18079 Validation Accuracy: 0.49520\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:    1.17487 Validation Accuracy: 0.49280\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:    1.14160 Validation Accuracy: 0.51420\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:    1.09016 Validation Accuracy: 0.51200\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:    1.08376 Validation Accuracy: 0.50220\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:    1.04542 Validation Accuracy: 0.51880\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:    1.04269 Validation Accuracy: 0.52820\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:    1.00331 Validation Accuracy: 0.52480\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:    1.00294 Validation Accuracy: 0.52320\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:    0.96014 Validation Accuracy: 0.52820\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:    0.93832 Validation Accuracy: 0.52380\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:    0.91907 Validation Accuracy: 0.52620\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:    0.92318 Validation Accuracy: 0.51640\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:    0.90152 Validation Accuracy: 0.52280\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:    0.88979 Validation Accuracy: 0.53280\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:    0.86883 Validation Accuracy: 0.52060\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:    0.79593 Validation Accuracy: 0.54000\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:    0.77510 Validation Accuracy: 0.54000\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:    0.81125 Validation Accuracy: 0.53220\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:    0.80047 Validation Accuracy: 0.52680\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:    0.72984 Validation Accuracy: 0.53480\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:    0.71339 Validation Accuracy: 0.53440\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:    0.67346 Validation Accuracy: 0.54740\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:    0.66574 Validation Accuracy: 0.54580\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:    0.66242 Validation Accuracy: 0.52240\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:    0.62895 Validation Accuracy: 0.52840\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:    0.59265 Validation Accuracy: 0.53540\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:    0.62346 Validation Accuracy: 0.52520\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:    0.59959 Validation Accuracy: 0.54380\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:    0.65179 Validation Accuracy: 0.53820\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:    0.59043 Validation Accuracy: 0.54860\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:    0.59095 Validation Accuracy: 0.53940\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:    0.59764 Validation Accuracy: 0.51860\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:    0.59760 Validation Accuracy: 0.51220\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:    0.57819 Validation Accuracy: 0.52420\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:    0.50594 Validation Accuracy: 0.53400\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:    0.49217 Validation Accuracy: 0.54160\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:    0.47473 Validation Accuracy: 0.53380\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:    0.49251 Validation Accuracy: 0.53920\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:    0.44447 Validation Accuracy: 0.53260\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:    0.46185 Validation Accuracy: 0.52400\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:    0.46265 Validation Accuracy: 0.54580\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:    0.45692 Validation Accuracy: 0.55040\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:    0.42216 Validation Accuracy: 0.55540\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:    0.40830 Validation Accuracy: 0.55780\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:    0.40708 Validation Accuracy: 0.55840\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:    0.40970 Validation Accuracy: 0.54100\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:    0.40893 Validation Accuracy: 0.54400\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:    0.40514 Validation Accuracy: 0.54060\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:    0.40358 Validation Accuracy: 0.55220\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:    0.41101 Validation Accuracy: 0.54340\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:    0.39550 Validation Accuracy: 0.54880\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:    0.35332 Validation Accuracy: 0.55600\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:    0.33676 Validation Accuracy: 0.55820\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:    0.36678 Validation Accuracy: 0.55140\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:    0.35224 Validation Accuracy: 0.55260\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:    0.38769 Validation Accuracy: 0.53880\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:    0.34884 Validation Accuracy: 0.53800\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:    0.33404 Validation Accuracy: 0.54360\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:    0.33230 Validation Accuracy: 0.54240\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:    0.34164 Validation Accuracy: 0.54400\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:    0.35066 Validation Accuracy: 0.54220\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:    0.34214 Validation Accuracy: 0.55820\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:    0.34903 Validation Accuracy: 0.55560\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:    0.32838 Validation Accuracy: 0.55100\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:    0.32027 Validation Accuracy: 0.56000\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:    0.30013 Validation Accuracy: 0.55800\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:    0.31973 Validation Accuracy: 0.55340\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:    0.28696 Validation Accuracy: 0.55140\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:    0.29047 Validation Accuracy: 0.54020\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:    0.27166 Validation Accuracy: 0.53620\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:    2.27280 Validation Accuracy: 0.19120\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:    2.24055 Validation Accuracy: 0.25280\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:    2.07814 Validation Accuracy: 0.28500\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:    2.00646 Validation Accuracy: 0.29460\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:    1.86834 Validation Accuracy: 0.30880\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:    2.06893 Validation Accuracy: 0.33120\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:    1.90514 Validation Accuracy: 0.36900\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:    1.65453 Validation Accuracy: 0.32800\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:    1.73659 Validation Accuracy: 0.36720\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:    1.72411 Validation Accuracy: 0.34420\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:    2.02226 Validation Accuracy: 0.36840\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:    1.77242 Validation Accuracy: 0.38180\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:    1.50320 Validation Accuracy: 0.39860\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:    1.57106 Validation Accuracy: 0.40280\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:    1.59339 Validation Accuracy: 0.39760\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:    1.85762 Validation Accuracy: 0.41920\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:    1.70025 Validation Accuracy: 0.43780\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:    1.42543 Validation Accuracy: 0.42620\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:    1.52976 Validation Accuracy: 0.38360\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:    1.52156 Validation Accuracy: 0.43240\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:    1.72822 Validation Accuracy: 0.44360\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:    1.58261 Validation Accuracy: 0.45280\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:    1.33671 Validation Accuracy: 0.44540\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:    1.49612 Validation Accuracy: 0.45840\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:    1.49711 Validation Accuracy: 0.44060\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:    1.63594 Validation Accuracy: 0.46520\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:    1.49318 Validation Accuracy: 0.46860\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:    1.22321 Validation Accuracy: 0.47040\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:    1.47491 Validation Accuracy: 0.46420\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:    1.41258 Validation Accuracy: 0.47280\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:    1.63219 Validation Accuracy: 0.43760\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:    1.45074 Validation Accuracy: 0.45800\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:    1.21503 Validation Accuracy: 0.48380\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:    1.39438 Validation Accuracy: 0.47680\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:    1.33199 Validation Accuracy: 0.49240\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:    1.48708 Validation Accuracy: 0.50160\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:    1.37618 Validation Accuracy: 0.47140\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:    1.11627 Validation Accuracy: 0.49840\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:    1.37088 Validation Accuracy: 0.50120\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:    1.24183 Validation Accuracy: 0.49680\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:    1.36322 Validation Accuracy: 0.50080\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:    1.32943 Validation Accuracy: 0.51540\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:    1.09839 Validation Accuracy: 0.49540\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:    1.29975 Validation Accuracy: 0.51580\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:    1.21991 Validation Accuracy: 0.50920\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:    1.29617 Validation Accuracy: 0.50520\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:    1.33112 Validation Accuracy: 0.50520\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:    0.98571 Validation Accuracy: 0.51720\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:    1.27299 Validation Accuracy: 0.52920\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:    1.12023 Validation Accuracy: 0.53680\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:    1.23049 Validation Accuracy: 0.52200\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:    1.25966 Validation Accuracy: 0.50980\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:    1.02281 Validation Accuracy: 0.52020\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:    1.25196 Validation Accuracy: 0.53640\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:    1.12273 Validation Accuracy: 0.53060\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:    1.15718 Validation Accuracy: 0.53020\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:    1.16928 Validation Accuracy: 0.53420\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:    0.95233 Validation Accuracy: 0.54200\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:    1.19934 Validation Accuracy: 0.54740\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:    1.06755 Validation Accuracy: 0.53400\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:    1.18608 Validation Accuracy: 0.54340\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:    1.09573 Validation Accuracy: 0.54380\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:    0.92527 Validation Accuracy: 0.53000\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:    1.16871 Validation Accuracy: 0.54260\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:    1.02624 Validation Accuracy: 0.53420\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:    1.08097 Validation Accuracy: 0.54920\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:    1.05051 Validation Accuracy: 0.54960\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:    0.86355 Validation Accuracy: 0.55760\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:    1.06047 Validation Accuracy: 0.56080\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:    1.02620 Validation Accuracy: 0.54700\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:    1.01599 Validation Accuracy: 0.55000\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:    0.96651 Validation Accuracy: 0.56640\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:    0.86414 Validation Accuracy: 0.56760\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:    1.02254 Validation Accuracy: 0.56540\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:    0.96491 Validation Accuracy: 0.54020\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:    0.99677 Validation Accuracy: 0.54980\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:    0.94741 Validation Accuracy: 0.57600\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:    0.81513 Validation Accuracy: 0.56400\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:    0.94586 Validation Accuracy: 0.58080\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:    0.93596 Validation Accuracy: 0.57280\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:    0.93775 Validation Accuracy: 0.55480\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:    0.90675 Validation Accuracy: 0.57360\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:    0.77775 Validation Accuracy: 0.57400\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:    0.90926 Validation Accuracy: 0.57340\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:    0.88866 Validation Accuracy: 0.57420\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:    0.88823 Validation Accuracy: 0.57400\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:    0.84040 Validation Accuracy: 0.58000\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:    0.82308 Validation Accuracy: 0.56440\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:    0.95338 Validation Accuracy: 0.58000\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:    0.82741 Validation Accuracy: 0.57600\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:    0.83624 Validation Accuracy: 0.57920\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:    0.81458 Validation Accuracy: 0.58100\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:    0.82380 Validation Accuracy: 0.57940\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:    0.87167 Validation Accuracy: 0.58440\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:    0.86302 Validation Accuracy: 0.57960\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:    0.83086 Validation Accuracy: 0.57700\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:    0.78204 Validation Accuracy: 0.57740\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:    0.72375 Validation Accuracy: 0.59320\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:    0.85464 Validation Accuracy: 0.59000\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:    0.79241 Validation Accuracy: 0.57640\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:    0.82457 Validation Accuracy: 0.58560\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:    0.75551 Validation Accuracy: 0.59680\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:    0.76656 Validation Accuracy: 0.59340\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:    0.83506 Validation Accuracy: 0.58840\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:    0.74809 Validation Accuracy: 0.58940\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:    0.80004 Validation Accuracy: 0.59020\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:    0.74818 Validation Accuracy: 0.59300\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:    0.71645 Validation Accuracy: 0.59300\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:    0.80118 Validation Accuracy: 0.59520\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:    0.75148 Validation Accuracy: 0.59600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, CIFAR-10 Batch 1:  Loss:    0.77288 Validation Accuracy: 0.59640\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:    0.67169 Validation Accuracy: 0.60120\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:    0.72099 Validation Accuracy: 0.58540\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:    0.76178 Validation Accuracy: 0.60340\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:    0.65686 Validation Accuracy: 0.60220\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:    0.79248 Validation Accuracy: 0.59020\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:    0.70151 Validation Accuracy: 0.59080\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:    0.69340 Validation Accuracy: 0.59420\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:    0.75284 Validation Accuracy: 0.61060\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:    0.64763 Validation Accuracy: 0.59900\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:    0.75010 Validation Accuracy: 0.58240\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:    0.64514 Validation Accuracy: 0.60400\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:    0.63602 Validation Accuracy: 0.60160\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:    0.74306 Validation Accuracy: 0.61580\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:    0.65103 Validation Accuracy: 0.60880\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:    0.73313 Validation Accuracy: 0.60580\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:    0.65476 Validation Accuracy: 0.60340\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:    0.64191 Validation Accuracy: 0.59540\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:    0.71855 Validation Accuracy: 0.61640\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:    0.58584 Validation Accuracy: 0.61440\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:    0.69517 Validation Accuracy: 0.60660\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:    0.62949 Validation Accuracy: 0.60260\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:    0.57882 Validation Accuracy: 0.60260\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:    0.69945 Validation Accuracy: 0.61380\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:    0.57421 Validation Accuracy: 0.60840\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:    0.62830 Validation Accuracy: 0.59940\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:    0.56570 Validation Accuracy: 0.61620\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:    0.55881 Validation Accuracy: 0.60720\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:    0.72221 Validation Accuracy: 0.61820\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:    0.55842 Validation Accuracy: 0.62200\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:    0.64717 Validation Accuracy: 0.60780\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:    0.58683 Validation Accuracy: 0.61920\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:    0.54792 Validation Accuracy: 0.61860\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:    0.64014 Validation Accuracy: 0.62280\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:    0.57214 Validation Accuracy: 0.61840\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:    0.63113 Validation Accuracy: 0.61840\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:    0.53655 Validation Accuracy: 0.62040\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:    0.58231 Validation Accuracy: 0.60660\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:    0.59180 Validation Accuracy: 0.62880\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:    0.50736 Validation Accuracy: 0.63240\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:    0.59394 Validation Accuracy: 0.61400\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:    0.54552 Validation Accuracy: 0.62400\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:    0.54753 Validation Accuracy: 0.60320\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:    0.60608 Validation Accuracy: 0.62960\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:    0.47603 Validation Accuracy: 0.63520\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:    0.58390 Validation Accuracy: 0.61400\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:    0.53042 Validation Accuracy: 0.61940\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:    0.57518 Validation Accuracy: 0.59060\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:    0.60495 Validation Accuracy: 0.62660\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:    0.46473 Validation Accuracy: 0.62840\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:    0.54457 Validation Accuracy: 0.61260\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:    0.53345 Validation Accuracy: 0.62640\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:    0.49493 Validation Accuracy: 0.62200\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:    0.54315 Validation Accuracy: 0.63400\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:    0.44127 Validation Accuracy: 0.62700\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:    0.54373 Validation Accuracy: 0.62300\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:    0.50364 Validation Accuracy: 0.63080\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:    0.48148 Validation Accuracy: 0.62160\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:    0.54277 Validation Accuracy: 0.63020\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:    0.44070 Validation Accuracy: 0.62560\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:    0.47882 Validation Accuracy: 0.62700\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:    0.47334 Validation Accuracy: 0.63400\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:    0.49539 Validation Accuracy: 0.60600\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:    0.54421 Validation Accuracy: 0.61620\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:    0.42584 Validation Accuracy: 0.64480\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:    0.46279 Validation Accuracy: 0.61700\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:    0.41711 Validation Accuracy: 0.63780\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:    0.45514 Validation Accuracy: 0.60700\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:    0.47357 Validation Accuracy: 0.62800\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:    0.36825 Validation Accuracy: 0.64500\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:    0.41970 Validation Accuracy: 0.62880\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:    0.39785 Validation Accuracy: 0.64420\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:    0.42297 Validation Accuracy: 0.59940\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:    0.43386 Validation Accuracy: 0.64340\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:    0.36092 Validation Accuracy: 0.63480\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:    0.44420 Validation Accuracy: 0.61960\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:    0.38211 Validation Accuracy: 0.64800\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:    0.41884 Validation Accuracy: 0.61820\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:    0.41529 Validation Accuracy: 0.63860\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:    0.35515 Validation Accuracy: 0.64620\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:    0.40368 Validation Accuracy: 0.63720\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:    0.39064 Validation Accuracy: 0.63980\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:    0.38965 Validation Accuracy: 0.63440\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:    0.42144 Validation Accuracy: 0.63660\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:    0.34466 Validation Accuracy: 0.64660\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:    0.40419 Validation Accuracy: 0.62460\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:    0.38995 Validation Accuracy: 0.63440\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:    0.37456 Validation Accuracy: 0.64880\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:    0.43549 Validation Accuracy: 0.62780\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:    0.35983 Validation Accuracy: 0.65260\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:    0.38864 Validation Accuracy: 0.64160\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:    0.36600 Validation Accuracy: 0.63280\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:    0.36370 Validation Accuracy: 0.63960\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:    0.42782 Validation Accuracy: 0.63280\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:    0.33717 Validation Accuracy: 0.65260\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:    0.38888 Validation Accuracy: 0.63600\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:    0.37218 Validation Accuracy: 0.64160\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:    0.31360 Validation Accuracy: 0.64120\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:    0.40195 Validation Accuracy: 0.63820\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:    0.33581 Validation Accuracy: 0.65080\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:    0.38338 Validation Accuracy: 0.63920\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:    0.35701 Validation Accuracy: 0.64140\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:    0.29638 Validation Accuracy: 0.64320\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:    0.38043 Validation Accuracy: 0.64480\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:    0.30541 Validation Accuracy: 0.65000\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:    0.37902 Validation Accuracy: 0.62780\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:    0.38273 Validation Accuracy: 0.64080\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:    0.30758 Validation Accuracy: 0.63760\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:    0.38899 Validation Accuracy: 0.65240\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:    0.33106 Validation Accuracy: 0.64580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, CIFAR-10 Batch 1:  Loss:    0.37072 Validation Accuracy: 0.64160\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:    0.34789 Validation Accuracy: 0.63000\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:    0.27965 Validation Accuracy: 0.65160\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:    0.33376 Validation Accuracy: 0.64460\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:    0.30134 Validation Accuracy: 0.64480\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:    0.35083 Validation Accuracy: 0.62700\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:    0.33736 Validation Accuracy: 0.62640\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:    0.26250 Validation Accuracy: 0.64620\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:    0.34319 Validation Accuracy: 0.64120\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:    0.30714 Validation Accuracy: 0.64300\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:    0.36145 Validation Accuracy: 0.64740\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:    0.32061 Validation Accuracy: 0.63580\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:    0.27195 Validation Accuracy: 0.64960\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:    0.31787 Validation Accuracy: 0.64480\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:    0.29395 Validation Accuracy: 0.64940\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:    0.33084 Validation Accuracy: 0.63840\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:    0.33147 Validation Accuracy: 0.64100\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:    0.25254 Validation Accuracy: 0.65200\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:    0.32160 Validation Accuracy: 0.63760\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:    0.29078 Validation Accuracy: 0.64760\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:    0.31712 Validation Accuracy: 0.64760\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:    0.35986 Validation Accuracy: 0.63600\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:    0.26644 Validation Accuracy: 0.65720\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:    0.33202 Validation Accuracy: 0.64220\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:    0.26938 Validation Accuracy: 0.64320\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:    0.33876 Validation Accuracy: 0.63740\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:    0.32436 Validation Accuracy: 0.64060\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:    0.25011 Validation Accuracy: 0.65240\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:    0.32365 Validation Accuracy: 0.62900\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:    0.27264 Validation Accuracy: 0.65080\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:    0.33537 Validation Accuracy: 0.64600\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:    0.30340 Validation Accuracy: 0.62700\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:    0.24994 Validation Accuracy: 0.65300\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:    0.30316 Validation Accuracy: 0.63160\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:    0.27194 Validation Accuracy: 0.64660\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:    0.30090 Validation Accuracy: 0.65680\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:    0.30313 Validation Accuracy: 0.62620\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:    0.24893 Validation Accuracy: 0.65440\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:    0.30071 Validation Accuracy: 0.64180\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:    0.26916 Validation Accuracy: 0.65560\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:    0.29375 Validation Accuracy: 0.65440\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:    0.32182 Validation Accuracy: 0.62120\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:    0.26360 Validation Accuracy: 0.66040\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:    0.29805 Validation Accuracy: 0.64340\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:    0.27002 Validation Accuracy: 0.65540\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:    0.28643 Validation Accuracy: 0.66300\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:    0.28667 Validation Accuracy: 0.62180\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:    0.25532 Validation Accuracy: 0.65040\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:    0.28153 Validation Accuracy: 0.65140\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:    0.27816 Validation Accuracy: 0.65400\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:    0.27062 Validation Accuracy: 0.65580\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:    0.30397 Validation Accuracy: 0.63660\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:    0.24617 Validation Accuracy: 0.65080\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:    0.26981 Validation Accuracy: 0.65500\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:    0.24948 Validation Accuracy: 0.64640\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:    0.28766 Validation Accuracy: 0.65160\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:    0.28479 Validation Accuracy: 0.62040\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:    0.23765 Validation Accuracy: 0.66120\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:    0.27426 Validation Accuracy: 0.64820\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:    0.26366 Validation Accuracy: 0.63960\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:    0.28745 Validation Accuracy: 0.65980\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:    0.27837 Validation Accuracy: 0.63480\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:    0.22461 Validation Accuracy: 0.65220\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:    0.24199 Validation Accuracy: 0.65360\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:    0.26657 Validation Accuracy: 0.64780\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:    0.26003 Validation Accuracy: 0.66560\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:    0.26920 Validation Accuracy: 0.62740\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:    0.20837 Validation Accuracy: 0.65660\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:    0.24356 Validation Accuracy: 0.65320\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:    0.25409 Validation Accuracy: 0.64560\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:    0.27354 Validation Accuracy: 0.66400\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:    0.30905 Validation Accuracy: 0.63920\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:    0.20869 Validation Accuracy: 0.66240\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:    0.22648 Validation Accuracy: 0.65660\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:    0.27093 Validation Accuracy: 0.64400\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:    0.26121 Validation Accuracy: 0.66400\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:    0.25918 Validation Accuracy: 0.64420\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:    0.21351 Validation Accuracy: 0.65800\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:    0.23536 Validation Accuracy: 0.65800\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:    0.23762 Validation Accuracy: 0.64460\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:    0.24413 Validation Accuracy: 0.65720\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:    0.26541 Validation Accuracy: 0.65160\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:    0.21431 Validation Accuracy: 0.64820\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:    0.24579 Validation Accuracy: 0.64980\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:    0.25286 Validation Accuracy: 0.65240\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:    0.25451 Validation Accuracy: 0.66540\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:    0.25578 Validation Accuracy: 0.64400\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:    0.18583 Validation Accuracy: 0.66140\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:    0.21886 Validation Accuracy: 0.65480\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:    0.24697 Validation Accuracy: 0.64500\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:    0.27344 Validation Accuracy: 0.66180\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:    0.23814 Validation Accuracy: 0.65160\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:    0.19013 Validation Accuracy: 0.65060\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:    0.21893 Validation Accuracy: 0.65440\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:    0.26109 Validation Accuracy: 0.63480\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:    0.24851 Validation Accuracy: 0.65640\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:    0.26973 Validation Accuracy: 0.64760\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:    0.20725 Validation Accuracy: 0.65380\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:    0.24631 Validation Accuracy: 0.64920\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:    0.21976 Validation Accuracy: 0.65460\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:    0.23899 Validation Accuracy: 0.66280\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:    0.24166 Validation Accuracy: 0.65440\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:    0.18347 Validation Accuracy: 0.65460\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:    0.22143 Validation Accuracy: 0.65720\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss:    0.25336 Validation Accuracy: 0.64060\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:    0.27837 Validation Accuracy: 0.65500\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:    0.25145 Validation Accuracy: 0.64340\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:    0.17237 Validation Accuracy: 0.64960\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:    0.23785 Validation Accuracy: 0.64440\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:    0.23872 Validation Accuracy: 0.65160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, CIFAR-10 Batch 1:  Loss:    0.24570 Validation Accuracy: 0.65820\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:    0.23870 Validation Accuracy: 0.65200\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:    0.18016 Validation Accuracy: 0.65320\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:    0.21894 Validation Accuracy: 0.65100\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:    0.21501 Validation Accuracy: 0.64800\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:    0.23600 Validation Accuracy: 0.65680\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:    0.23931 Validation Accuracy: 0.65580\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:    0.16811 Validation Accuracy: 0.64040\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:    0.23666 Validation Accuracy: 0.65420\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:    0.21470 Validation Accuracy: 0.65620\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:    0.21547 Validation Accuracy: 0.65360\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:    0.26673 Validation Accuracy: 0.64420\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:    0.17048 Validation Accuracy: 0.65820\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:    0.23261 Validation Accuracy: 0.65720\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:    0.22942 Validation Accuracy: 0.64740\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:    0.29393 Validation Accuracy: 0.63900\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:    0.26342 Validation Accuracy: 0.64100\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:    0.18280 Validation Accuracy: 0.65000\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:    0.21941 Validation Accuracy: 0.66600\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:    0.20316 Validation Accuracy: 0.65620\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:    0.22684 Validation Accuracy: 0.62700\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:    0.25556 Validation Accuracy: 0.65300\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:    0.16868 Validation Accuracy: 0.64320\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:    0.19653 Validation Accuracy: 0.64980\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:    0.21640 Validation Accuracy: 0.65220\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:    0.25107 Validation Accuracy: 0.62680\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:    0.24244 Validation Accuracy: 0.64300\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:    0.16189 Validation Accuracy: 0.65180\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:    0.18779 Validation Accuracy: 0.65660\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:    0.19494 Validation Accuracy: 0.65100\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:    0.22210 Validation Accuracy: 0.63700\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:    0.22936 Validation Accuracy: 0.64440\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:    0.14687 Validation Accuracy: 0.65800\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:    0.24127 Validation Accuracy: 0.64720\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:    0.21006 Validation Accuracy: 0.64440\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:    0.21716 Validation Accuracy: 0.62640\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:    0.21743 Validation Accuracy: 0.64900\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:    0.14933 Validation Accuracy: 0.66120\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:    0.21119 Validation Accuracy: 0.65760\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:    0.19553 Validation Accuracy: 0.65140\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:    0.21015 Validation Accuracy: 0.62760\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:    0.26074 Validation Accuracy: 0.63660\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:    0.16989 Validation Accuracy: 0.66040\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:    0.22492 Validation Accuracy: 0.64860\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:    0.22368 Validation Accuracy: 0.63180\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:    0.18388 Validation Accuracy: 0.63220\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:    0.22497 Validation Accuracy: 0.64700\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:    0.13771 Validation Accuracy: 0.65660\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:    0.17900 Validation Accuracy: 0.66540\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:    0.19631 Validation Accuracy: 0.65260\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:    0.16594 Validation Accuracy: 0.63500\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:    0.21800 Validation Accuracy: 0.64300\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:    0.16591 Validation Accuracy: 0.64960\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:    0.20611 Validation Accuracy: 0.66500\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:    0.21086 Validation Accuracy: 0.65080\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:    0.18866 Validation Accuracy: 0.63120\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:    0.20152 Validation Accuracy: 0.64620\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:    0.15015 Validation Accuracy: 0.65620\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:    0.17777 Validation Accuracy: 0.66060\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:    0.20556 Validation Accuracy: 0.64780\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:    0.17151 Validation Accuracy: 0.64040\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:    0.22441 Validation Accuracy: 0.64600\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:    0.13470 Validation Accuracy: 0.65960\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:    0.18910 Validation Accuracy: 0.65540\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:    0.16717 Validation Accuracy: 0.65380\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:    0.18402 Validation Accuracy: 0.63860\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:    0.20282 Validation Accuracy: 0.64460\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:    0.17126 Validation Accuracy: 0.65500\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:    0.17607 Validation Accuracy: 0.66460\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:    0.17400 Validation Accuracy: 0.66020\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:    0.17981 Validation Accuracy: 0.64680\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:    0.18789 Validation Accuracy: 0.64960\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:    0.15779 Validation Accuracy: 0.64880\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:    0.17464 Validation Accuracy: 0.65200\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:    0.18566 Validation Accuracy: 0.66020\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:    0.16194 Validation Accuracy: 0.65540\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:    0.20920 Validation Accuracy: 0.64860\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:    0.13978 Validation Accuracy: 0.65400\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:    0.15695 Validation Accuracy: 0.65140\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:    0.19344 Validation Accuracy: 0.66080\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:    0.19108 Validation Accuracy: 0.64800\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:    0.19007 Validation Accuracy: 0.64880\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:    0.14167 Validation Accuracy: 0.64980\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:    0.15093 Validation Accuracy: 0.66300\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:    0.18712 Validation Accuracy: 0.65380\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:    0.14886 Validation Accuracy: 0.64480\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:    0.19438 Validation Accuracy: 0.64060\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:    0.13172 Validation Accuracy: 0.64840\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:    0.15930 Validation Accuracy: 0.65500\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:    0.15764 Validation Accuracy: 0.64720\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:    0.13891 Validation Accuracy: 0.65240\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:    0.18245 Validation Accuracy: 0.64440\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:    0.13219 Validation Accuracy: 0.65400\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:    0.16066 Validation Accuracy: 0.66400\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:    0.14760 Validation Accuracy: 0.65520\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:    0.16089 Validation Accuracy: 0.64800\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:    0.17457 Validation Accuracy: 0.64520\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:    0.15172 Validation Accuracy: 0.64700\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss:    0.17315 Validation Accuracy: 0.65400\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:    0.14798 Validation Accuracy: 0.65360\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:    0.15542 Validation Accuracy: 0.65340\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:    0.16246 Validation Accuracy: 0.64320\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss:    0.15906 Validation Accuracy: 0.64580\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:    0.15712 Validation Accuracy: 0.66140\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:    0.16293 Validation Accuracy: 0.65880\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:    0.15753 Validation Accuracy: 0.64820\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:    0.16494 Validation Accuracy: 0.64640\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:    0.12033 Validation Accuracy: 0.65480\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:    0.15549 Validation Accuracy: 0.65900\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:    0.15850 Validation Accuracy: 0.64440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89, CIFAR-10 Batch 1:  Loss:    0.16680 Validation Accuracy: 0.64700\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:    0.16723 Validation Accuracy: 0.63740\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:    0.11383 Validation Accuracy: 0.64900\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:    0.17298 Validation Accuracy: 0.65560\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:    0.14525 Validation Accuracy: 0.64900\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:    0.19422 Validation Accuracy: 0.65660\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:    0.17387 Validation Accuracy: 0.63860\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:    0.12064 Validation Accuracy: 0.65020\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:    0.15806 Validation Accuracy: 0.65520\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:    0.15179 Validation Accuracy: 0.65180\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:    0.17030 Validation Accuracy: 0.64980\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:    0.17738 Validation Accuracy: 0.64340\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:    0.12440 Validation Accuracy: 0.64420\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:    0.15173 Validation Accuracy: 0.65360\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:    0.14568 Validation Accuracy: 0.64920\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:    0.18994 Validation Accuracy: 0.64520\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:    0.19507 Validation Accuracy: 0.63820\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:    0.11143 Validation Accuracy: 0.64360\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:    0.14731 Validation Accuracy: 0.64760\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:    0.14517 Validation Accuracy: 0.63980\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:    0.16339 Validation Accuracy: 0.62940\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:    0.21291 Validation Accuracy: 0.64060\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:    0.13569 Validation Accuracy: 0.64480\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:    0.13421 Validation Accuracy: 0.64880\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:    0.13482 Validation Accuracy: 0.63040\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:    0.17320 Validation Accuracy: 0.63760\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:    0.19080 Validation Accuracy: 0.62680\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:    0.13128 Validation Accuracy: 0.63780\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:    0.12364 Validation Accuracy: 0.65140\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:    0.15034 Validation Accuracy: 0.62220\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:    0.17965 Validation Accuracy: 0.62760\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:    0.16160 Validation Accuracy: 0.64280\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:    0.14189 Validation Accuracy: 0.63880\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:    0.15569 Validation Accuracy: 0.65220\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:    0.14068 Validation Accuracy: 0.62380\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:    0.16742 Validation Accuracy: 0.63720\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:    0.18823 Validation Accuracy: 0.64420\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:    0.12714 Validation Accuracy: 0.65180\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:    0.15359 Validation Accuracy: 0.64860\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:    0.17006 Validation Accuracy: 0.60300\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:    0.17768 Validation Accuracy: 0.65180\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:    0.16168 Validation Accuracy: 0.64000\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:    0.15033 Validation Accuracy: 0.64420\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:    0.17867 Validation Accuracy: 0.64860\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:    0.14397 Validation Accuracy: 0.63400\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:    0.16763 Validation Accuracy: 0.64980\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:    0.17253 Validation Accuracy: 0.63360\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:    0.16668 Validation Accuracy: 0.64240\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:    0.16036 Validation Accuracy: 0.65800\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:    0.16287 Validation Accuracy: 0.62100\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:    0.16624 Validation Accuracy: 0.64620\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:    0.16927 Validation Accuracy: 0.64160\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:    0.16901 Validation Accuracy: 0.63640\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:    0.14865 Validation Accuracy: 0.65620\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:    0.16065 Validation Accuracy: 0.61580\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.595703125\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff9a408e550>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
